{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how easy is to create a new model with **AIdictive**!\n",
    "MNIST is the \"hello world\" of the Machine Learning community, so let's train a model on it.\n",
    "\n",
    "We will use a ResNet-18 network (https://arxiv.org/abs/1512.03385) to fit the data.\n",
    "Although you can train this model with a CPU, training times will be greatly reduced if you have a **GPU**.\n",
    "\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T02:12:40.326509Z",
     "start_time": "2019-11-01T02:12:39.153910Z"
    }
   },
   "outputs": [],
   "source": [
    "import aidictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, that's all. With one import we can do a lot!\n",
    "\n",
    "\n",
    "# Constants definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T02:12:40.330983Z",
     "start_time": "2019-11-01T02:12:40.328371Z"
    }
   },
   "outputs": [],
   "source": [
    "# The number of classes should be 10 because we want to classify digits from 0 to 9.\n",
    "# Do not change this value.\n",
    "N_CLASSES = 10\n",
    "# Number of input channels.\n",
    "# MNIST images are black and white, if the number of channels is > 1 the black and\n",
    "# white channel is going to by copy in all the channels.\n",
    "# Channels = 3 only makes sense if you are going to use a pretrained ResNet model,\n",
    "# if you are going to train a ResNet from scratch, as in this example, 1 channel is\n",
    "# the best election.\n",
    "CHANNELS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T02:12:40.485619Z",
     "start_time": "2019-11-01T02:12:40.332825Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility. If you run this in CPU you should get\n",
    "# exactly the same results. In GPU the results will change, but the performance\n",
    "# of the model should be very similar.\n",
    "aidictive.seed(124)\n",
    "\n",
    "# Get MINST train and test datasets with the indicated number of channels.\n",
    "ds_train, ds_test = aidictive.data.mnist(\"input\", num_output_channels=CHANNELS)\n",
    "# Create a ResNet model.\n",
    "model = aidictive.models.resnet(N_CLASSES, input_channels=CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T02:12:40.493327Z",
     "start_time": "2019-11-01T02:12:40.487201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create and object that will perform the training.\n",
    "# By default the trainer is going to move the model to the GPU.\n",
    "trainer = aidictive.trainer.Trainer(model)\n",
    "\n",
    "# Define loss and metric.\n",
    "trainer.set_loss(\"cross_entropy\")\n",
    "trainer.set_metric(\"accuracy\")\n",
    "\n",
    "# Use RAdam optimizer.\n",
    "trainer.set_optimizer(\"radam\")\n",
    "\n",
    "# Log loss and metric every 100 batches.\n",
    "trainer.set_train_logger(\"interval\", epoch_interval=1, batch_interval=200)\n",
    "\n",
    "# Set train and test datasets and define batch_sizes.\n",
    "trainer.set_train_data(ds_train, batch_size=64)\n",
    "trainer.set_test_data(ds_test, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T02:43:02.306810Z",
     "start_time": "2019-11-01T02:12:40.495589Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data loader...\n",
      "Creating logger...\n",
      "Creating optimizer...\n",
      "Batch 200 ended in 0.6221s.\n",
      "metric:\t0.893515625\n",
      "loss:\t0.350421632300131\n",
      "Batch 400 ended in 0.6507s.\n",
      "metric:\t0.921796875\n",
      "loss:\t0.2608513527410105\n",
      "Batch 600 ended in 0.7066s.\n",
      "metric:\t0.9344791666666666\n",
      "loss:\t0.22254822491978607\n",
      "Batch 800 ended in 0.5970s.\n",
      "metric:\t0.9419140625\n",
      "loss:\t0.20206313605769538\n",
      "Epoch 1 ended in 604.5422s. Batches: 938.\n",
      "metric:\t0.9453833333333334\n",
      "loss:\t0.19082717477778594\n",
      "Batch 200 ended in 0.5893s.\n",
      "metric:\t0.98109375\n",
      "loss:\t0.08235932566225529\n",
      "Batch 400 ended in 0.6475s.\n",
      "metric:\t0.98421875\n",
      "loss:\t0.06322165003293775\n",
      "Batch 600 ended in 0.6563s.\n",
      "metric:\t0.985390625\n",
      "loss:\t0.058098892613391705\n",
      "Batch 800 ended in 0.6245s.\n",
      "metric:\t0.98626953125\n",
      "loss:\t0.05385594178456813\n",
      "Epoch 2 ended in 604.7689s. Batches: 938.\n",
      "metric:\t0.98665\n",
      "loss:\t0.051456614507486426\n",
      "Batch 200 ended in 0.5906s.\n",
      "metric:\t0.99171875\n",
      "loss:\t0.029400076083256864\n",
      "Batch 400 ended in 0.6087s.\n",
      "metric:\t0.9921875\n",
      "loss:\t0.02795420644659316\n",
      "Batch 600 ended in 0.6482s.\n",
      "metric:\t0.9916145833333333\n",
      "loss:\t0.029599040021712427\n",
      "Batch 800 ended in 0.6095s.\n",
      "metric:\t0.99173828125\n",
      "loss:\t0.028539684725692495\n",
      "Epoch 3 ended in 612.4841s. Batches: 938.\n",
      "metric:\t0.99185\n",
      "loss:\t0.028339168775004024\n"
     ]
    }
   ],
   "source": [
    "# Let's train the model for three epochs with different learning rate.\n",
    "trainer.set_lr(0.01)\n",
    "trainer.fit()\n",
    "trainer.set_lr(0.001)\n",
    "trainer.fit()\n",
    "trainer.set_lr(0.0001)\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T04:23:25.277282Z",
     "start_time": "2019-10-31T04:23:25.273888Z"
    }
   },
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T02:43:10.045112Z",
     "start_time": "2019-11-01T02:43:02.309932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data loader...\n",
      "Creating logger...\n",
      "Epoch 1 ended in 7.7307s. Batches: 10.\n",
      "metric:\t0.993\n",
      "loss:\t0.0228057787835598\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You did it! You have trained a ResNet model on the famous MNIST dataset with no effort.\n",
    "The test accuracy shoud be arround **99.3%**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
